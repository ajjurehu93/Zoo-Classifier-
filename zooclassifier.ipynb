{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "from imageio import imread\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data=[]\n",
    "labels=[]\n",
    "\n",
    "cats=os.listdir(\"cats\")\n",
    "for cat in cats:\n",
    "    imag=imread(\"cats/\"+cat)\n",
    "    temp = Image.fromarray(imag, 'RGB')\n",
    "    resized_image = temp.resize((50, 50))\n",
    "    data.append(np.array(resized_image))\n",
    "    labels.append(0)\n",
    "    \n",
    "dogs=os.listdir(\"dogs\")\n",
    "for dog in dogs:\n",
    "    imag=imread(\"dogs/\"+dog)\n",
    "    temp=Image.fromarray(imag,'RGB')\n",
    "    resized_image=temp.resize((50,50))\n",
    "    data.append(np.array(resized_image))\n",
    "    labels.append(1)\n",
    "\n",
    "panda=os.listdir(\"panda\")\n",
    "for element in panda:\n",
    "    imag=imread(\"panda/\"+element,as_gray=False, pilmode=\"RGB\")\n",
    "    temp=Image.fromarray(imag,'RGB')\n",
    "    resized_image=temp.resize((50,50))\n",
    "    data.append(np.array(resized_image))\n",
    "    labels.append(2)\n",
    "\n",
    "animals=np.array(data)\n",
    "labels=np.array(labels)\n",
    "    \n",
    "np.save(\"animals\",animals)\n",
    "np.save(\"labels\",labels)\n",
    "\n",
    "#shuffling data and labels\n",
    "idx=np.random.permutation(len(animals))\n",
    "animals,labels=animals[idx],labels[idx]\n",
    "\n",
    "num_classes=len(np.unique(labels))\n",
    "data_length=len(animals)\n",
    "\n",
    "#splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(animals, labels, test_size=0.25, random_state=11111)\n",
    "\n",
    "\n",
    "#one hot encoding\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train=to_categorical(y_train, num_classes)\n",
    "y_test=to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2250, 50, 50, 3)\n",
      "(2250, 3)\n",
      "(750, 50, 50, 3)\n",
      "(750, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validating data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2250 samples, validate on 750 samples\n",
      "Epoch 1/15\n",
      "2250/2250 [==============================] - 2s 1ms/step - loss: 1.2117 - acc: 0.3178 - val_loss: 1.1024 - val_acc: 0.3307\n",
      "Epoch 2/15\n",
      "2250/2250 [==============================] - 0s 153us/step - loss: 1.0950 - acc: 0.3769 - val_loss: 1.1087 - val_acc: 0.3240\n",
      "Epoch 3/15\n",
      "2250/2250 [==============================] - 0s 155us/step - loss: 1.1062 - acc: 0.3364 - val_loss: 1.1097 - val_acc: 0.3240\n",
      "Epoch 4/15\n",
      "2250/2250 [==============================] - 0s 136us/step - loss: 1.1013 - acc: 0.3364 - val_loss: 1.0983 - val_acc: 0.3240\n",
      "Epoch 5/15\n",
      "2250/2250 [==============================] - 0s 132us/step - loss: 1.0925 - acc: 0.3716 - val_loss: 1.0947 - val_acc: 0.3307\n",
      "Epoch 6/15\n",
      "2250/2250 [==============================] - 0s 151us/step - loss: 1.0945 - acc: 0.3342 - val_loss: 1.0927 - val_acc: 0.3373\n",
      "Epoch 7/15\n",
      "2250/2250 [==============================] - 0s 155us/step - loss: 1.0906 - acc: 0.4431 - val_loss: 1.0861 - val_acc: 0.5013\n",
      "Epoch 8/15\n",
      "2250/2250 [==============================] - 0s 144us/step - loss: 1.0862 - acc: 0.5044 - val_loss: 1.0857 - val_acc: 0.5040\n",
      "Epoch 9/15\n",
      "2250/2250 [==============================] - 0s 148us/step - loss: 1.0873 - acc: 0.4858 - val_loss: 1.0909 - val_acc: 0.4187\n",
      "Epoch 10/15\n",
      "2250/2250 [==============================] - 0s 151us/step - loss: 1.0907 - acc: 0.4164 - val_loss: 1.0949 - val_acc: 0.3813\n",
      "Epoch 11/15\n",
      "2250/2250 [==============================] - 0s 165us/step - loss: 1.0919 - acc: 0.4040 - val_loss: 1.0888 - val_acc: 0.4480\n",
      "Epoch 12/15\n",
      "2250/2250 [==============================] - 0s 148us/step - loss: 1.0856 - acc: 0.4858 - val_loss: 1.0822 - val_acc: 0.5227\n",
      "Epoch 13/15\n",
      "2250/2250 [==============================] - 0s 147us/step - loss: 1.0821 - acc: 0.5151 - val_loss: 1.0822 - val_acc: 0.5067\n",
      "Epoch 14/15\n",
      "2250/2250 [==============================] - 0s 138us/step - loss: 1.0818 - acc: 0.5044 - val_loss: 1.0845 - val_acc: 0.4400\n",
      "Epoch 15/15\n",
      "2250/2250 [==============================] - 0s 147us/step - loss: 1.0796 - acc: 0.4538 - val_loss: 1.0702 - val_acc: 0.5040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ff25a44b70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "#X_train  = X_train.reshape(-1,50*50*3)\n",
    "#X_test  = X_test.reshape(-1,50*50*3)\n",
    "\n",
    "X_train = X_train.reshape(len(X_train),50*50*3)\n",
    "X_test = X_test.reshape(len(X_test),50*50*3)\n",
    "\n",
    "model=models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(100, activation='relu', input_shape=(50*50*3,)))\n",
    "model.add(layers.Dense(100, activation='sigmoid'))\n",
    "model.add(layers.Dense(100, activation='sigmoid'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,y_train,batch_size=800,epochs=15, verbose=1,validation_data=(X_test,y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
