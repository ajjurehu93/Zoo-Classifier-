{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "from imageio import imread\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data=[]\n",
    "labels=[]\n",
    "\n",
    "cats=os.listdir(\"cats\")\n",
    "for cat in cats:\n",
    "    imag=imread(\"cats/\"+cat)\n",
    "    temp = Image.fromarray(imag, 'RGB')\n",
    "    resized_image = temp.resize((50, 50))\n",
    "    data.append(np.array(resized_image))\n",
    "    labels.append(0)\n",
    "    \n",
    "dogs=os.listdir(\"dogs\")\n",
    "for dog in dogs:\n",
    "    imag=imread(\"dogs/\"+dog)\n",
    "    temp=Image.fromarray(imag,'RGB')\n",
    "    resized_image=temp.resize((50,50))\n",
    "    data.append(np.array(resized_image))\n",
    "    labels.append(1)\n",
    "\n",
    "panda=os.listdir(\"panda\")\n",
    "for element in panda:\n",
    "    imag=imread(\"panda/\"+element,as_gray=False, pilmode=\"RGB\")\n",
    "    temp=Image.fromarray(imag,'RGB')\n",
    "    resized_image=temp.resize((50,50))\n",
    "    data.append(np.array(resized_image))\n",
    "    labels.append(2)\n",
    "\n",
    "animals=np.array(data)\n",
    "labels=np.array(labels)\n",
    "    \n",
    "np.save(\"animals\",animals)\n",
    "np.save(\"labels\",labels)\n",
    "\n",
    "#shuffling data and labels\n",
    "idx=np.random.permutation(len(animals))\n",
    "animals,labels=animals[idx],labels[idx]\n",
    "\n",
    "num_classes=len(np.unique(labels))\n",
    "data_length=len(animals)\n",
    "\n",
    "#splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(animals, labels, test_size=0.25, random_state=11111)\n",
    "\n",
    "\n",
    "#one hot encoding\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train=to_categorical(y_train, num_classes)\n",
    "y_test=to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2250, 50, 50, 3)\n",
      "(2250, 3)\n",
      "(750, 50, 50, 3)\n",
      "(750, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validating data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-633058d724e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Adam'\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "#X_train  = X_train.reshape(-1,50*50*3)\n",
    "#X_test  = X_test.reshape(-1,50*50*3)\n",
    "\n",
    "X_train = X_train.reshape(len(X_train),50*50*3)\n",
    "X_test = X_test.reshape(len(X_test),50*50*3)\n",
    "\n",
    "model=models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(100, activation='relu', input_shape=(50*50*3,)))\n",
    "model.add(layers.Dense(100, activation='sigmoid'))\n",
    "model.add(layers.Dense(100, activation='sigmoid'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam'(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,y_train,batch_size=800,epochs=15, verbose=1,validation_data=(X_test,y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
